package tools

import (
	"context"
	"fmt"
	"regexp"
	"strings"
	"time"

	"github.com/go-rod/rod"
	"github.com/go-rod/rod/lib/launcher"
	"github.com/spf13/viper"
)

// Browser provides a web browsing capability for AI Agents.
type Browser struct {
	agents []*Agent
}

// NewBrowser initializes a new Browser instance.
func NewBrowser() *Browser {
	return &Browser{
		agents: []*Agent{
			NewAgent(
				context.Background(),
				NewConn(),
				"browser",
				"search",
				viper.GetViper().GetString("ai.researcher.system"),
				viper.GetViper().GetString("ai.researcher.tasks.results"),
			),
			NewAgent(
				context.Background(),
				NewConn(),
				"browser",
				"search",
				viper.GetViper().GetString("ai.researcher.system"),
				viper.GetViper().GetString("ai.researcher.tasks.content"),
			),
		},
	}
}

/*
Use the browser to search the web for information relevant to the query.
It follows the following process:

1. Search duckduckgo for the query generated by the Context Manager.
2. Use a temporary agent to select the most relevant URLs from the search results.
3. Open each URL and use another temporary agent to extract the relevant content.
4. Return the content.
*/
func (b *Browser) Use(query string) (string, error) {
	fmt.Printf("Browser.Use called with query: %s\n", query)

	query = strings.ReplaceAll(query, `"`, "")
	query = strings.ReplaceAll(query, " ", "+")

	// Initialize the launcher without specifying UserDataDir to use default.
	// Set Headless to false to see the browser window for debugging.
	// Change to true in production to run the browser in the background.
	l := launcher.New().Headless(false) // Change to true in production

	// Launch the browser
	u, err := l.Launch()
	if err != nil {
		fmt.Printf("Failed to launch browser: %v\n", err)
		return "", fmt.Errorf("failed to launch browser: %w", err)
	}
	fmt.Printf("Browser launched with URL: %s\n", u)

	// Handle Cleanup without expecting a return value
	defer l.Cleanup()

	// Connect to the browser
	browser := rod.New().ControlURL(u).MustConnect()
	defer func() {
		if err := browser.Close(); err != nil {
			fmt.Printf("Error closing browser: %v\n", err)
		}
	}()

	// Open the DuckDuckGo search page
	searchURL := "https://duckduckgo.com/?t=h_&q=" + query
	fmt.Printf("Opening search URL: %s\n", searchURL)

	// Corrected: Use MustPage with string URL
	searchPage := browser.MustPage(searchURL).MustWindowFullscreen()

	urls, err := b.results(query, searchPage)
	if err != nil {
		fmt.Printf("Error getting search results: %v\n", err)
		return "", fmt.Errorf("failed to get search results: %w", err)
	}

	if len(urls) == 0 {
		fmt.Println("No URLs found in search results")
		return "", nil
	}

	fmt.Printf("Found %d URLs. Processing up to 3.\n", len(urls))

	results := make([]string, 0, 3)
	for i, url := range urls {
		if i >= 3 {
			break
		}

		// Scroll to the current URL in the search results, and highlight it.
		searchPage.MustEval(
			`(url) => {
				const link = document.querySelector('[href="'+url+'"]');
				if (link) {
					link.scrollIntoView({ behavior: 'smooth', block: 'center' });
				}
				// Animate the highlight
				link.style.backgroundColor = 'yellow';
				link.style.transition = 'background-color 0.5s';
				setTimeout(() => {
					link.style.backgroundColor = '';
				}, 1000);
			}`, url)

		time.Sleep(1 * time.Second)

		fmt.Printf("Processing URL %d: %s\n", i+1, url)

		// Open the URL in a new page
		newPage := browser.MustPage(url)

		fmt.Printf("Opened page %d successfully.\n", i+1)

		// Wait for the page to load
		fmt.Printf("Waiting for page %d to load...\n", i+1)
		if err := newPage.WaitLoad(); err != nil {
			fmt.Printf("Failed to load page %d: %v\n", i+1, err)
			newPage.Close()
			continue
		}

		fmt.Printf("Page %d loaded successfully.\n", i+1)

		text, err := b.content(query, newPage)
		if err != nil {
			fmt.Printf("Error extracting content from page %d: %v\n", i+1, err)
			continue
		}
		fmt.Printf("Retrieved text from page %d: %s\n", i+1, text)

		results = append(results, text)

		// Close the new page
		if err := newPage.Close(); err != nil {
			fmt.Printf("Error closing page %d: %v\n", i+1, err)
		} else {
			fmt.Printf("Closed page %d successfully.\n", i+1)
		}

		// Optional: Sleep briefly to allow the browser to process
		time.Sleep(1 * time.Second)
	}

	// Return the aggregated results
	fmt.Println("Aggregating results.")
	return strings.Join(results, "\n\n"), nil
}

func (b *Browser) results(query string, page *rod.Page) ([]string, error) {
	// Wait for the page to load
	fmt.Println("Waiting for search page to load...")
	if err := page.WaitLoad(); err != nil {
		return nil, fmt.Errorf("failed to load search page: %w", err)
	}

	fmt.Println("Search page loaded successfully.")

	// Get the HTML content of the search results
	html, err := page.HTML()
	if err != nil {
		return nil, fmt.Errorf("failed to get HTML of search page: %w", err)
	}

	ctx := strings.ReplaceAll(
		b.agents[0].user, "{query}", query,
	)
	ctx = strings.ReplaceAll(
		ctx, "{results}", html,
	)

	// Use the "results" agent to select relevant URLs
	urlsChannel := b.agents[0].Generate(
		context.Background(),
		ctx,
	)

	// Accumulate the streaming response
	var agentResponse strings.Builder
	for chunk := range urlsChannel {
		agentResponse.WriteString(chunk)
	}

	// Parse the URLs from the agent's response
	var relevantURLs []string
	lines := strings.Split(agentResponse.String(), "\n")
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if strings.HasPrefix(line, "- ") {
			url := strings.TrimSpace(strings.TrimPrefix(line, "- "))
			// Additional cleanup: remove any leading/trailing quotes if present
			url = strings.Trim(url, "\"'")
			relevantURLs = append(relevantURLs, url)
		}
	}

	fmt.Printf("Extracted %d relevant URLs\n", len(relevantURLs))

	return relevantURLs, nil
}

func (b *Browser) content(query string, page *rod.Page) (string, error) {
	// Retrieve all text from the page
	content, err := page.Element("body")
	if err != nil {
		return "", fmt.Errorf("failed to find body in page %w", err)
	}

	text, err := content.Text()
	if err != nil {
		return "", fmt.Errorf("failed to get text from body in page %w", err)
	}

	ctx := strings.ReplaceAll(
		b.agents[1].user, "{query}", query,
	)
	ctx = strings.ReplaceAll(
		ctx, "{content}", text,
	)

	// Use the "content" agent to extract relevant information
	contentChannel := b.agents[1].Generate(context.Background(), ctx)

	// Accumulate the streaming response
	var relevantContent strings.Builder

	for chunk := range contentChannel {
		relevantContent.WriteString(chunk)
	}

	relevantContent.WriteString("\n")

	re := regexp.MustCompile("(?s)```markdown(.*?)```")
	match := re.FindStringSubmatch(relevantContent.String())
	if len(match) > 0 {
		return fmt.Sprintf(
			"RESEARCH RESULTS FOR: %s\n\n%s", query, match[1],
		), nil
	}

	return relevantContent.String(), nil
}
